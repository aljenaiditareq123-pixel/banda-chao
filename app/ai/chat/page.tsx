'use client';

import { useState, useRef, useEffect } from 'react';
import Link from 'next/link';
import { ChatAgent, AgentMessage, AgentResponse } from '@/lib/ai/agents';
import { EnhancedVoiceManager, defaultArabicVoice } from '@/lib/ai/voice';

export default function AIChatPage() {
  const [messages, setMessages] = useState<AgentMessage[]>([
    {
      role: 'assistant',
      content: 'ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Chat AI - Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ ğŸ˜Š\n\nğŸ¤ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù„Ù„ØªØ­Ø¯Ø« Ù…Ø¹ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø©!\n\nÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:\nâ€¢ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹\nâ€¢ Ù†ØµØ§Ø¦Ø­ ÙŠÙˆÙ…ÙŠØ©\nâ€¢ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±\nâ€¢ Ø·Ø±Ù‚ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø¯Ø®Ù„\nâ€¢ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±!\n\nØªØ­Ø¯Ø« Ù…Ø¹ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø©! ğŸ¤',
      timestamp: new Date()
    }
  ]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [speaking, setSpeaking] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const recognitionRef = useRef<any>(null);
  const voiceManagerRef = useRef<EnhancedVoiceManager | null>(null);
  const chatAgent = useRef(new ChatAgent()).current;

  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // Initialize Voice Manager with saved settings
  useEffect(() => {
    if (typeof window !== 'undefined' && 'speechSynthesis' in window) {
      // Load saved settings
      const saved = localStorage.getItem('voiceSettings');
      let settings = defaultArabicVoice;
      
      if (saved) {
        try {
          const parsed = JSON.parse(saved);
          settings = {
            ...defaultArabicVoice,
            lang: parsed.lang || defaultArabicVoice.lang,
            rate: parsed.rate || defaultArabicVoice.rate,
            pitch: parsed.pitch || defaultArabicVoice.pitch,
            volume: parsed.volume || defaultArabicVoice.volume,
          };
        } catch (e) {
          console.error('Error loading voice settings:', e);
        }
      }

      voiceManagerRef.current = new EnhancedVoiceManager(settings);
      voiceManagerRef.current.setCallbacks({
        onStart: () => setSpeaking(true),
        onEnd: () => setSpeaking(false),
        onError: () => setSpeaking(false),
      });
    }

    return () => {
      if (voiceManagerRef.current) {
        voiceManagerRef.current.stop();
      }
    };
  }, []);

  // Initialize Speech Recognition
  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      
      if (SpeechRecognition) {
        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'ar-SA'; // Arabic, can also use 'en-US' or 'zh-CN'

        recognition.onstart = () => {
          setIsListening(true);
        };

        recognition.onresult = (event: any) => {
          const transcript = event.results[0][0].transcript;
          setInput(transcript);
          setIsListening(false);
          // Auto send after recognition
          setTimeout(() => {
            handleSendMessage(transcript);
          }, 500);
        };

        recognition.onerror = (event: any) => {
          console.error('Speech recognition error:', event.error);
          setIsListening(false);
          if (event.error === 'no-speech') {
            alert('Ù„Ù… Ø£Ø³Ù…Ø¹ Ø£ÙŠ ØµÙˆØª. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.');
          } else if (event.error === 'not-allowed') {
            alert('ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.');
          }
        };

        recognition.onend = () => {
          setIsListening(false);
        };

        recognitionRef.current = recognition;
      }
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  const startListening = () => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.start();
        setInput('');
      } catch (error) {
        console.error('Error starting recognition:', error);
        alert('Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.');
      }
    } else {
      alert('Ù…ÙŠØ²Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ù…ØªØµÙØ­Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Chrome Ø£Ùˆ Edge.');
    }
  };

  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
      setIsListening(false);
    }
  };

  const handleSendMessage = async (messageText?: string) => {
    const textToSend = messageText || input;
    if (!textToSend.trim() || loading) return;

    const userMessage: AgentMessage = {
      role: 'user',
      content: textToSend,
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setLoading(true);

    try {
      const response: AgentResponse = await chatAgent.process(textToSend);
      
      const assistantMessage: AgentMessage = {
        role: 'assistant',
        content: formatResponse(response),
        timestamp: new Date()
      };

      setMessages(prev => [...prev, assistantMessage]);
      
      // Speak the response with enhanced voice
      if (voiceManagerRef.current) {
        voiceManagerRef.current.speak(assistantMessage.content, true);
      }
    } catch (error) {
      console.error('Error:', error);
      const errorMessage: AgentMessage = {
        role: 'assistant',
        content: 'âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setLoading(false);
    }
  };

  const handleSend = () => {
    handleSendMessage();
  };

  const stopSpeaking = () => {
    if (voiceManagerRef.current) {
      voiceManagerRef.current.stop();
    }
  };

  const formatResponse = (response: AgentResponse): string => {
    let content = response.message + '\n\n';
    
    if (response.suggestions && response.suggestions.length > 0) {
      content += response.suggestions.map(s => `â€¢ ${s}`).join('\n');
    }

    if (response.actions && response.actions.length > 0) {
      content += '\n\nğŸ“‹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:\n';
      content += response.actions.map((a, i) => 
        `${i + 1}. ${a.description} (${a.priority === 'high' ? 'Ø¹Ø§Ù„ÙŠ' : a.priority === 'medium' ? 'Ù…ØªÙˆØ³Ø·' : 'Ù…Ù†Ø®ÙØ¶'})`
      ).join('\n');
    }

    return content;
  };

  const quickQuestions = [
    'Ù…Ø§ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ØŸ',
    'Ù†ØµÙŠØ­ØªÙƒ Ù„ÙŠ Ø§Ù„ÙŠÙˆÙ…',
    'ÙƒÙŠÙ Ø£Ù†Ø´Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙÙŠ Ø§Ù„ØµÙŠÙ†ØŸ',
    'ÙƒÙŠÙ Ø£Ø­Ù‚Ù‚ Ø¯Ø®Ù„ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ØŸ',
    'Ù…Ø§ Ø£Ù‡Ù… 3 Ø£Ø´ÙŠØ§Ø¡ ÙŠØ¬Ø¨ ÙØ¹Ù„Ù‡Ø§ Ø§Ù„Ø¢Ù†ØŸ'
  ];

  const isSpeechSupported = typeof window !== 'undefined' && 
    ((window as any).SpeechRecognition || (window as any).webkitSpeechRecognition);

  return (
    <div className="min-h-screen bg-gray-50 flex flex-col">
      {/* Header */}
      <div className="bg-white border-b border-gray-200 p-4">
        <div className="max-w-4xl mx-auto flex items-center justify-between">
          <div>
            <h1 className="text-2xl font-bold text-gray-900">ğŸ¤– Chat AI - Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ</h1>
            <p className="text-gray-600 text-sm mt-1">
              {chatAgent.getStatus()} â€¢ {isSpeechSupported ? 'ğŸ¤ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¨Ø§Ø´Ø±Ø©!' : 'âš ï¸ Ø§Ù„ØªØ­Ø¯Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… - Ø§Ø³ØªØ®Ø¯Ù… Chrome Ø£Ùˆ Edge'}
            </p>
          </div>
          <Link
            href="/ai/voice-settings"
            className="px-4 py-2 text-sm bg-gray-100 text-gray-700 rounded-lg hover:bg-gray-200 transition"
          >
            ğŸšï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª
          </Link>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4">
        <div className="max-w-4xl mx-auto space-y-4">
          {messages.map((message, index) => (
            <div
              key={index}
              className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
            >
              <div
                className={`max-w-[80%] rounded-lg p-4 ${
                  message.role === 'user'
                    ? 'bg-red-600 text-white'
                    : 'bg-white border border-gray-200 text-gray-900'
                }`}
              >
                <div className="whitespace-pre-wrap">{message.content}</div>
                {message.timestamp && (
                  <div className={`text-xs mt-2 ${
                    message.role === 'user' ? 'text-red-100' : 'text-gray-500'
                  }`}>
                    {message.timestamp.toLocaleTimeString('ar', { hour: '2-digit', minute: '2-digit' })}
                  </div>
                )}
              </div>
            </div>
          ))}
          {loading && (
            <div className="flex justify-start">
              <div className="bg-white border border-gray-200 rounded-lg p-4">
                <div className="flex items-center space-x-2">
                  <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-red-600"></div>
                  <span className="text-gray-600">Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±...</span>
                </div>
              </div>
            </div>
          )}
          {isListening && (
            <div className="flex justify-end">
              <div className="bg-red-600 text-white rounded-lg p-4">
                <div className="flex items-center space-x-2">
                  <div className="animate-pulse w-3 h-3 bg-white rounded-full"></div>
                  <span>ğŸ¤ Ø£Ø³ØªÙ…Ø¹ Ø¥Ù„ÙŠÙƒ... ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†</span>
                </div>
              </div>
            </div>
          )}
          {speaking && (
            <div className="flex justify-start">
              <div className="bg-green-50 border border-green-200 rounded-lg p-4">
                <div className="flex items-center space-x-2">
                  <div className="animate-pulse w-3 h-3 bg-green-600 rounded-full"></div>
                  <span className="text-green-700">ğŸ”Š Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¯Ø«...</span>
                </div>
              </div>
            </div>
          )}
          <div ref={messagesEndRef} />
        </div>
      </div>

      {/* Quick Questions */}
      <div className="bg-white border-t border-gray-200 p-4">
        <div className="max-w-4xl mx-auto mb-2">
          <p className="text-sm text-gray-600 mb-2">ğŸ’¡ Ø£Ø³Ø¦Ù„Ø© Ø³Ø±ÙŠØ¹Ø©:</p>
          <div className="flex flex-wrap gap-2">
            {quickQuestions.map((q, i) => (
              <button
                key={i}
                onClick={() => {
                  setInput(q);
                  handleSendMessage(q);
                }}
                className="px-3 py-1.5 text-sm bg-gray-100 text-gray-700 rounded-full hover:bg-gray-200 transition"
              >
                {q}
              </button>
            ))}
          </div>
        </div>
      </div>

      {/* Input */}
      <div className="bg-white border-t border-gray-200 p-4">
        <div className="max-w-4xl mx-auto flex space-x-2">
          {/* Voice Button */}
          {isSpeechSupported && (
            <button
              onClick={isListening ? stopListening : startListening}
              disabled={speaking}
              className={`px-4 py-3 rounded-lg transition ${
                isListening
                  ? 'bg-red-600 text-white animate-pulse'
                  : speaking
                  ? 'bg-gray-300 text-gray-500 cursor-not-allowed'
                  : 'bg-gray-100 text-gray-700 hover:bg-gray-200'
              }`}
              title={isListening ? 'Ø§Ø¶ØºØ· Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„' : speaking ? 'Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ AI Ù…Ù† Ø§Ù„ØªØ­Ø¯Ø«' : 'Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«'}
            >
              {isListening ? (
                <span className="text-xl">ğŸ›‘</span>
              ) : (
                <span className="text-xl">ğŸ¤</span>
              )}
            </button>
          )}

          {/* Text Input */}
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => {
              if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleSend();
              }
            }}
            placeholder={isSpeechSupported ? "Ø§ÙƒØªØ¨ Ø£Ùˆ Ø§Ø¶ØºØ· ğŸ¤ Ù„Ù„ØªØ­Ø¯Ø«..." : "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§... (Ø§Ø¶ØºØ· Enter Ù„Ù„Ø¥Ø±Ø³Ø§Ù„)"}
            className="flex-1 px-4 py-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-red-500 focus:border-red-500"
            disabled={loading || isListening}
          />

          {/* Send/Stop Speaking Button */}
          {speaking ? (
            <button
              onClick={stopSpeaking}
              className="px-4 py-3 bg-green-600 text-white rounded-lg hover:bg-green-700 transition flex items-center space-x-2"
              title="Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ­Ø¯Ø«"
            >
              <span className="animate-pulse">ğŸ”Š</span>
              <span>Ø¥ÙŠÙ‚Ø§Ù</span>
            </button>
          ) : (
            <button
              onClick={handleSend}
              disabled={loading || !input.trim() || isListening || speaking}
              className="px-6 py-3 bg-red-600 text-white rounded-lg hover:bg-red-700 disabled:opacity-50 disabled:cursor-not-allowed transition"
            >
              {loading ? 'Ø¬Ø§Ø±ÙŠ...' : 'Ø¥Ø±Ø³Ø§Ù„'}
            </button>
          )}
        </div>

        {/* Instructions */}
        {isSpeechSupported && (
          <div className="max-w-4xl mx-auto mt-2">
            <p className="text-xs text-gray-500 text-center">
              ğŸ’¡ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ ğŸ¤ Ù„Ù„ØªØ­Ø¯Ø« Ù…Ø¨Ø§Ø´Ø±Ø© - ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            </p>
          </div>
        )}
      </div>
    </div>
  );
}
